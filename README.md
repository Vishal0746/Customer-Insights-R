# Customer-Insights-R

<h3>| Procedure For Execution </h3>
&nbsp;&nbsp;<li>Load The Appropriate Working Directory for dataset </li>
 <li>Load All Required Model</li>
 <li>Select The Part To Run</li>
 <li>Locate Graph in Plot secssion</li>
 &nbsp;&nbsp;
 
 <h3>| Introduction </h3>
 In today's competitive business environment, it's 
critical for companies to have a deep understanding of their 
customers' needs and preferences. Organizations frequently use 
customer insight, which is gathering and analyzing data to 
acquire insights into customer behavior, to do this. In this 
study, we provide a method for data analysis that extracts 
insights from customer data by using decision trees, random 
forests, logistic regression, and heat map plots, among other 
machine learning approaches. Our method entails cleaning and 
preprocessing the data, utilizing decision trees and random 
forests to analyze it and find patterns and associations, followed 
by logistic regression to forecast potential customer behavior. 
The associations between various factors are also visualized
using a heat map plot and correlation matrix. These insights 
can assist companies in making data-driven decisions that will 
improve client retention, boost sales, and improve the overall 
customer experience.
</br>

<h3>| METHODOLOGY & RESULTS </h3>

<li>Data Cleaning</li>
 <li>Logistic Regression</li>
 <li>Decision Tree</li>
 <li>Random Forest</li>
 
 <h3>| Obtained Accuracy</h3>
 </br>
 The system's overall performance was quite good, 
both the logistic regression and random forest models' 
accuracy rates were around 80%, with the logistic 
regression model's accuracy being somewhat higher 
(80.45% vs. 79.7%), compared to the random forest model. 
According to the confusion matrix and statistics, the 
random forest model had 1411 true negatives, 137 false 
negatives, 276 false positives, and 284 true positives, 
compared to the logistic regression model's 1430 true 
negatives, 310 erroneous negatives, 118 false positives, 
and 250 true positives.
Additionally, both models had relatively large false 
negative rates, indicating that they were less successful at 
identifying consumers who would leave. The accuracy rate 
for the decision tree model was lower (76.66%), and it also 
had a significant false negative rate. In terms of accuracy, 
the logistic regression model outperformed the other two 
models evaluated the best overall. However, additional 
research may be required to enhance the models' 
performance, notably in lowering the false-negative rate

 <h3>| Output</h3>
![image](https://user-images.githubusercontent.com/89679996/234952012-a327e2e0-5f71-43e6-abca-509ba23b9c8e.png)
</br>
![image](https://user-images.githubusercontent.com/89679996/234952042-639b2e61-f4dc-40b5-bd5d-ae3a4955be16.png)
</br>
![image](https://user-images.githubusercontent.com/89679996/234952086-4f58800b-e2c7-4f82-8698-e449baf32a3c.png)
</br>
![image](https://user-images.githubusercontent.com/89679996/234952108-42ee3069-6136-4ddb-bd91-116611e50174.png)


